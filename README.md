# AI Resource Repository & Foundational Papers

This repository contains curated AI resources, notes, research papers, and interview preparation materials. The resources are grouped by topic and include foundational AI papers for study and reference.

---

## 1. Behavioral & Interview Prep

- **Behavioral Questions:** [behavioral](https://chatgpt.com/share/68909e99-0488-8006-accc-e7b67c60c03a)  
- **Interview Questions:** [interview_questions](https://chatgpt.com/share/688247e6-56ec-8001-bb44-1c9f8aabbc21)  
- **IQ Preparation:** [IQ](https://chatgpt.com/share/6884a772-98a4-8001-af02-5ad694ec2b0b)  

---

## 2. Statistics & Math

- **Statistics Notes:** [statistics_notes](https://chatgpt.com/share/672aa663-4998-8001-b1da-2517dc3b5646)  

---

## 3. NLP & Transformers

- **NLP Overview:** [nlp_overview](https://chatgpt.com/share/6873c436-69c4-800a-bf50-235b14fd11d5)  
- **Transformer Notes:** [transformer](https://chatgpt.com/share/6874f5c6-de80-800a-bf5f-7d561799b1db)  

### Key NLP Papers
**Text Representation & Embeddings**  
- TF-IDF (1975) – Sparck Jones  
- Latent Dirichlet Allocation (LDA, 2003) – Blei, Ng, Jordan  
- Word2Vec (2013) – Mikolov et al. [Paper](https://arxiv.org/abs/1301.3781)  
- GloVe (2014) – Pennington et al. [Paper](https://nlp.stanford.edu/pubs/glove.pdf)  
- ELMo (2018) – Peters et al. [Paper](https://arxiv.org/abs/1802.05365)  

**Transformers & LLMs**  
- Attention Is All You Need (2017) – Vaswani et al. [Paper](https://arxiv.org/abs/1706.03762)  
- BERT (2018) – Devlin et al. [Paper](https://arxiv.org/abs/1810.04805)  
- GPT (2018) – Radford et al. [Blog](https://openai.com/research/language-unsupervised)  
- GPT-2 (2019) – Radford et al. [Blog](https://openai.com/research/gpt-2)  
- GPT-3 (2020) – Brown et al. [Paper](https://arxiv.org/abs/2005.14165)  
- T5 (2020) – Raffel et al. [Paper](https://arxiv.org/abs/1910.10683)  
- PaLM (2022) – Chowdhery et al. [Paper](https://arxiv.org/abs/2204.02311)  
- LLaMA (2023) – Touvron et al. [Paper](https://arxiv.org/abs/2302.13971)  

**Evaluation & Ethics**  
- Datasheets for Datasets (2020) – Gebru et al. [Paper](https://arxiv.org/abs/1803.09010)  
- CheckList (2021) – Ribeiro et al. [Paper](https://arxiv.org/abs/2005.04118)  
- On the Dangers of Stochastic Parrots (2020) – Bender et al. [Paper](https://dl.acm.org/doi/10.1145/3442188.3445922)  

---

## 4. Vision

- **Vision Notes:** [vision](https://chatgpt.com/share/687b69ce-ca50-8001-b9bc-d4e48794ba6)  

**Key Vision Papers**  
- LeNet-5 (1998) – LeCun et al. [Paper](https://scholar.google.com/scholar?q=Gradient-Based+Learning+Applied+to+Document+Recognition)  
- VGG (2015) – Simonyan & Zisserman [Paper](https://arxiv.org/abs/1409.1556)  
- ResNet (2015) – He et al. [Paper](https://arxiv.org/abs/1512.03385)  

---

## 5. Generative Models

- **VAE Notes:** [vae_notes](https://chatgpt.com/share/68876d17-049c-8001-ba0a-342a75e37d45)  
- **GAN Notes:** [gan_notes](https://chatgpt.com/share/6889ff96-ee7c-8001-b8b0-79c79ee1ef30)  

**Key Papers**  
- Auto-Encoding Variational Bayes (2013) – Kingma & Welling [Paper](https://arxiv.org/abs/1312.6114)  
- β-VAE (2016) – Higgins et al. [Paper](https://openreview.net/forum?id=Sy2fzU9gl)  
- GAN (2014) – Goodfellow et al. [Paper](https://arxiv.org/abs/1406.2661)  
- DCGAN (2017) – Radford et al. [Paper](https://arxiv.org/abs/1511.06434)  
- WGAN (2017) – Arjovsky et al. [Paper](https://arxiv.org/abs/1701.07875)  

---

## 6. Reinforcement Learning & Agents

- **RL Notes:** [reinforcement_learning](https://chatgpt.com/share/688df8a2-9f14-8001-bb8e-a9736e9aece4)  
- **Agent Design:** [agent_design](https://chatgpt.com/share/68919f6a-8158-8001-888d-6cdf46e97f9b)  

**Key RL Papers**  
- Q-Learning (1992) – Watkins & Dayan [Paper](https://www.cs.rhul.ac.uk/home/qq/sem1/IntroQlearning.pdf)  
- DQN (2013) – Mnih et al. [Paper](https://www.nature.com/articles/nature14236)  
- PPO (2017) – Schulman et al. [Paper](https://arxiv.org/abs/1707.06347)  
- RLHF: InstructGPT (2022) – Ouyang et al. [Paper](https://arxiv.org/abs/2203.02155)  

---

## 7. Multimodal Learning

- **Multimodal Notes:** [multimodal_learning](https://chatgpt.com/share/687cd147-9090-8001-bffe-b001a3e459cd)  

**Key Papers**  
- CLIP (2021) – Radford et al. [Blog](https://openai.com/research/clip)  
- ALIGN (2021) – Jia et al. [Paper](https://arxiv.org/abs/2102.05918)  
- BLIP (2022) – Li et al. [Paper](https://arxiv.org/abs/2201.12086)  
- GPT-4V (2023) – OpenAI  
- Whisper (2023) – OpenAI [Blog](https://openai.com/research/whisper)  

---

## 8. Graph Neural Networks

- **GNN Notes:** [gnn_notes](https://chatgpt.com/share/687f3195-8310-8001-9a0c-8e291b12ef21)  

---

## 9. Readme & Documentation

- [readme_files_1](https://chatgpt.com/share/68791a9a-62b4-800a-ac8f-ba76892a00cd)  
- [readme_files_2](https://chatgpt.com/share/687b6b80-75a8-8001-9d4d-8aa56debf5a6)  

---

**Usage:**  
Clone this repository to access AI notes, foundational research papers, and curated learning resources across NLP, Vision, RL, Generative AI, Multimodal AI, and Agent design.

