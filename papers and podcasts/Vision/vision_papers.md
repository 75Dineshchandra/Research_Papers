# üì∏ Foundational & Modern Computer Vision Papers

A curated list of influential computer vision papers, grouped by topic. Each paper helped shape the evolution of visual understanding in AI.

---

## üß± 1. CNN Foundations & Image Classification

- **1989**: *Backpropagation Applied to Handwritten Zip Code Recognition* ‚Äì LeCun et al.  
  _Early CNN concept; precursor to LeNet._
- **1998**: *Gradient-Based Learning Applied to Document Recognition (LeNet-5)* ‚Äì LeCun et al.  
  _One of the earliest convolutional neural network architectures._
- **2012**: *ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)* ‚Äì Krizhevsky et al.  
  _Revived deep learning by winning ImageNet 2012._
- **2014**: *Visualizing and Understanding Convolutional Networks* ‚Äì Zeiler & Fergus  
  _Introduced DeconvNet to interpret CNNs._
- **2014**: *Network In Network (NiN)* ‚Äì Lin et al.  
  _Introduced MLP layers inside convolutions for more expressiveness._
- **2015**: *Very Deep Convolutional Networks (VGG)* ‚Äì Simonyan & Zisserman  
  _Stacked 3x3 convolutions; simplified deep networks._
- **2015**: *Deep Residual Learning for Image Recognition (ResNet)* ‚Äì He et al.  
  _Introduced skip connections; enabled 100+ layer training._

---

## üîç 2. Object Detection

- **2001**: *Rapid Object Detection using a Boosted Cascade of Simple Features* ‚Äì Viola & Jones  
  _Haar-like features + cascaded classifiers._
- **2014**: *R-CNN: Rich Feature Hierarchies* ‚Äì Girshick et al.  
  _First deep-learning-based object detector using region proposals._
- **2015**: *Fast R-CNN* ‚Äì Girshick  
  _Improved training/inference speed using RoI pooling._
- **2015**: *Faster R-CNN* ‚Äì Ren et al.  
  _Introduced Region Proposal Networks (RPNs)._
- **2016**: *You Only Look Once (YOLO)* ‚Äì Redmon et al.  
  _Unified detection and classification in a single pass._
- **2017**: *Feature Pyramid Networks (FPN)* ‚Äì Lin et al.  
  _Used feature maps at multiple scales for detection._

---

## üéØ 3. Image Segmentation

- **2015**: *Fully Convolutional Networks (FCN)* ‚Äì Long et al.  
  _First end-to-end semantic segmentation CNN._
- **2016**: *U-Net* ‚Äì Ronneberger et al.  
  _Encoder-decoder design with skip connections; widely used in biomedical tasks._
- **2017**: *Mask R-CNN* ‚Äì He et al.  
  _Extended Faster R-CNN to include pixel-level instance segmentation._

---

## üß† 4. Vision Transformers & Hybrid Models

- **2020**: *An Image is Worth 16x16 Words (ViT)* ‚Äì Dosovitskiy et al.  
  _Applied pure transformers to image patches._
- **2021**: *Swin Transformer* ‚Äì Liu et al.  
  _Introduced local windowed attention; hierarchical structure._
- **2021**: *DETR* ‚Äì Carion et al.  
  _End-to-end detection via transformer-based encoder-decoder._

---

## üé® 5. Generative Vision Models

- **2015**: *Laplacian Pyramid GAN* ‚Äì Denton et al.  
  _Multiscale generative modeling._
- **2016**: *Improved Training of GANs* ‚Äì Salimans et al.  
  _Introduced techniques like feature matching, mini-batch discrimination._
- **2018**: *BigGAN* ‚Äì Brock et al.  
  _Large-scale GAN training on ImageNet._
- **2021**: *Latent Diffusion Models* ‚Äì Rombach et al.  
  _Stable Diffusion: high-quality, controllable image synthesis._

---

## üß¨ 6. Multimodal & Vision-Language

- **2015**: *Show and Tell* ‚Äì Vinyals et al.  
  _CNN + LSTM for image captioning._
- **2016**: *Show, Attend and Tell* ‚Äì Xu et al.  
  _Introduced attention mechanism in captioning._
- **2021**: *CLIP* ‚Äì Radford et al. (OpenAI)  
  _Joint image-text embeddings via contrastive learning._
- **2021**: *ALIGN* ‚Äì Jia et al. (Google)  
  _Scaled CLIP-style models using noisy web data._
- **2022**: *BLIP* ‚Äì Li et al.  
  _Bootstrapped pretraining with language-image pairs._
- **2023**: *Segment Anything* ‚Äì Kirillov et al.  
  _Zero-shot segmentation via promptable SAM model._

---

## üîß 7. Training Techniques & Optimization in Vision

- **2010**: *Xavier Initialization* ‚Äì Glorot & Bengio  
  _Controlled variance propagation in deep nets._
- **2015**: *Batch Normalization* ‚Äì Ioffe & Szegedy  
  _Normalization for stable training._
- **2017**: *Bag of Tricks for Image Classification* ‚Äì He et al.  
  _Engineering tweaks for better accuracy._
- **2018**: *Mixup* ‚Äì Zhang et al.  
  _Data augmentation through image-label interpolation._
- **2019**: *CutMix* ‚Äì Yun et al.  
  _Replaces patches of images with others + mixes labels._

---

Let me know if you'd like links, GitHub repos, PDF access, or influence maps between these models.

